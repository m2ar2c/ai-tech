<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 技术核心解析报告 - 幻灯片 16</title>
    <style>
        :root { color-scheme: light; }
        * { box-sizing: border-box; }
        body {
            margin: 0;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            background: radial-gradient(circle at 20% 20%, #16213E 0%, #0F172A 45%, #020617 100%);
            font-family: 'HarmonyOS Sans SC', 'PingFang SC', 'Microsoft YaHei', 'Source Han Sans SC', sans-serif;
            color: #1D2939;
        }
        .slide {
            width: 1280px;
            height: 720px;
            background: #FFFFFF;
            border-radius: 32px;
            position: relative;
            padding: 96px 112px 120px 112px;
            box-shadow: 0 32px 120px rgba(15, 23, 42, 0.45);
            overflow: hidden;
        }
        .slide.cover {
            background: linear-gradient(140deg, #165DFF 0%, #36CFFB 55%, #5AD7F7 100%);
            color: #FFFFFF;
        }
        .slide.cover .badge {
            background: rgba(255, 255, 255, 0.18);
            color: #FFFFFF;
        }
        .slide.cover .slide-title {
            color: #FFFFFF;
            font-size: 64px;
        }
        .slide.cover .slide-subtitle {
            color: rgba(255, 255, 255, 0.85);
            font-size: 28px;
        }
        .slide.cover .content ul li {
            color: rgba(255, 255, 255, 0.9);
        }
        .badge {
            position: absolute;
            top: 36px;
            left: 48px;
            padding: 6px 18px;
            border-radius: 999px;
            background: rgba(22, 93, 255, 0.12);
            color: #165DFF;
            font-size: 18px;
            font-weight: 600;
            letter-spacing: 0.02em;
        }
        .slide-title {
            margin: 0;
            font-size: 46px;
            line-height: 1.2;
            color: #101828;
            font-weight: 700;
            letter-spacing: 0.01em;
        }
        .slide-subtitle {
            margin: 18px 0 48px 0;
            font-size: 24px;
            line-height: 1.6;
            color: #475467;
            max-width: 780px;
        }
        .content {
            font-size: 24px;
            line-height: 1.6;
            color: #1D2939;
        }
        .content ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }
        .content li {
            margin-bottom: 20px;
            position: relative;
            padding-left: 28px;
        }
        .content li::before {
            content: '';
            position: absolute;
            left: 0;
            top: 12px;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #165DFF;
            box-shadow: 0 0 0 5px rgba(22, 93, 255, 0.2);
        }
        .slide.cover .content li::before {
            background: rgba(255, 255, 255, 0.9);
            box-shadow: 0 0 0 5px rgba(255, 255, 255, 0.2);
        }
        .nav-hint {
            position: absolute;
            bottom: 40px;
            left: 56px;
            font-size: 18px;
            color: #98A2B3;
            letter-spacing: 0.02em;
        }
        .slide.cover .nav-hint {
            color: rgba(255, 255, 255, 0.7);
        }
        .page-number {
            position: absolute;
            bottom: 40px;
            right: 56px;
            font-size: 20px;
            color: #98A2B3;
            font-weight: 500;
            letter-spacing: 0.04em;
        }
        .slide.cover .page-number {
            color: rgba(255, 255, 255, 0.75);
        }
    </style>
</head>
<body>
    <div class="slide" data-slide="16">
            <div class="badge">四、大模型自注意力学习机制</div>
            <h1 class="slide-title">4.4 自注意力机制的优势与应用</h1>
            <div class="content">
                <ul>
                <li>相比传统的 RNN/LSTM 架构，自注意力机制具有以下显著优势：并行计算能力：RNN 每一步的输出都依赖前一步，导致必须顺序执行</li>
                <li>而 Transformer 使用自注意力机制，所有位置可以同时计算注意力，实现完全并行，训练速度比 RNN 快 10 倍以上</li>
                <li>长距离依赖建模：传统 RNN/LSTM 通过隐藏状态传递信息，在长文本中容易遗忘开头的信息</li>
                <li>而自注意力机制允许序列中任意两个位置直接交互，距离为$O(1)$，能够更好地捕捉长距离依赖关系</li>
                </ul>
            </div>
            <div class="nav-hint">使用 ← → 键切换</div>
            <div class="page-number"></div>
    </div>
    <script src="navigation.js"></script>
</body>
</html>